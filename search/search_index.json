{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Dataguard","text":"<p>Dataguard is a Python package for performing data validation on dataframe objects. </p> <p>It provides a flexible and extensible framework for defining validation rules, ensuring that your data meets quality and consistency requirements.</p> <p>To get started, please see the Getting Started</p> <p>For API documentation, please see the API Reference.</p>"},{"location":"api/","title":"API Reference","text":"<p>Enums used in the validation library. These enums define various constants used throughout the library for error levels, validation types, and check cases.</p> <p>config_input must use the following naming conventions.</p>"},{"location":"api/#dataguard.validator.validator.Validator","title":"Validator","text":"<p>Validator class for validating DataFrames against a defined schema.</p> Source code in <code>src/dataguard/validator/validator.py</code> <pre><code>class Validator:\n    \"\"\"Validator class for validating DataFrames against a defined schema.\"\"\"\n\n    error_collector = ErrorCollector()\n\n    @classmethod\n    def config_from_mapping(\n        cls,\n        config: Mapping[str, str | Sequence | Mapping],\n        collect_exceptions: bool = True,\n        logger: logging.Logger = logger,\n    ) -&gt; Validator:\n        \"\"\"Creates a Validator instance from a configuration mapping.\n\n        Args:\n            config (Mapping[str, str | Sequence | Mapping]): Configuration\n                mapping for the DataFrame schema.\n            collect_exceptions (bool, optional): Whether to collect exceptions\n                during the schema creation. Defaults to True.\n            logger (logging.Logger, optional): Logger instance for logging.\n                Defaults to the module logger.\n\n        Examples:\n            The command is either a user-defined function or a string that\n            maps to a function that will be used to validate the DataFrame.\n\n            The following commands are available:\n\n                'is_equal_to',\n                'is_equal_to_or_both_missing',\n                'is_greater_than_or_equal_to',\n                'is_greater_than',\n                'is_less_than_or_equal_to',\n                'is_less_than',\n                'is_not_equal_to',\n                'is_not_equal_to_and_not_both_missing',\n                'is_unique',\n                'is_duplicated',\n                'is_in',\n                'is_null',\n                'is_not_null'\n\n            &gt;&gt;&gt; config_input = {\n                    \"name\": \"example_schema\",\n                    \"columns\": [\n                        {\n                            \"id\": \"column1\",\n                            \"data_type\": \"integer\",\n                            \"nullable\": False,\n                            \"unique\": True,\n                            \"required\": True,\n                            \"checks\": [\n                                {\n                                    \"command\": \"is_equal_to\",\n                                    \"subject\": [\"column2\"]\n                                }\n                            ]\n                        },\n                    \"ids\": [\"column1\"],\n                    \"metadata\": {\"description\": \"Example DataFrame schema\"},\n                    \"checks\": [\n                        {\n                            'name': 'example_check',\n                            'error_level': 'warning',\n                            'error_msg': 'This is an example check',\n                            'command': 'is_in',\n                            'subject': ['column1'],\n                            'arg_values': [1, 2]\n                        }\n                    ]\n                }\n\n        Returns:\n            Validator: An instance of the Validator class with the schema\n                created from the provided configuration mapping.\n\n        \"\"\"\n        validator = cls()\n        try:\n            validator.df_schema = get_df_schema(config)\n            logger.info('DFSchema created successfully')\n\n        except KeyError as err:\n            error_handler(\n                err=err,\n                err_level='critical',\n                message=f'Missing the following key in config input: {err.args[0]}',  # noqa: E501\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n\n        except (AttributeError, TypeError) as err:\n            error_handler(\n                err=err,\n                err_level='critical',\n                message=f'Invalid config type: {err.args[0]}',\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n\n        except ValidationError as err:\n            error_handler(\n                err=err,\n                err_level='critical',\n                message=f'Invalid config type: {[error[\"loc\"] for error in err.errors()]}',  # noqa: E501\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n\n        except Exception as err:\n            exception_handler(\n                err=err,\n                err_level='critical',\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n\n            logger.error('Failed to create DFSchema from configuration')\n\n        return validator\n\n    def validate(\n        self,\n        dataframe: Mapping[str, list] | pl.DataFrame,\n        lazy_validation: bool = True,\n        collect_exceptions: bool = True,\n        logger: logging.Logger = logger,\n    ) -&gt; None:\n        \"\"\"Validates a DataFrame against the defined schema.\n\n        Args:\n            dataframe (Mapping[str, list] | pl.DataFrame): The input data\n                as a mapping or a Polars DataFrame.\n            lazy_validation (bool, optional): Whether to perform lazy validation.\n                Defaults to True.\n            collect_exceptions (bool, optional): Whether to collect exceptions\n                during validation. Defaults to True.\n            logger (logging.Logger, optional): Logger instance for logging.\n                Defaults to the module logger.\n\n        Raises:\n            Exception: If an error occurs during validation and\n                collect_exceptions is False.\n\n        \"\"\"  # noqa: E501\n        try:\n            if not getattr(self, 'df_schema', None):\n                logger.error('DataFrame schema is not defined')\n                return\n\n            logger.info('Starting DataFrame validation')\n            if isinstance(dataframe, Mapping):\n                dataframe = convert_mapping_to_dataframe(\n                    dataframe=dataframe,\n                    collect_exceptions=collect_exceptions,\n                    logger=logger,\n                )\n\n            if not getattr(dataframe, 'shape', None):\n                logger.error('DataFrame is not valid')\n                return\n\n            logger.info(f'Building DataFrame schema {self.df_schema.name =}')\n            df_schema = self.df_schema.build()\n\n            try:\n                logger.info('Casting DataFrame Types')\n                dataframe = dataframe.cast({\n                    col.id: validation_type_mapper[col.data_type]\n                    for col in self.df_schema.columns\n                    if col.id in dataframe.columns\n                })\n\n                logger.info('Starting DataFrame validation')\n                dataframe.pipe(df_schema.validate, lazy=lazy_validation)\n\n            except pl.exceptions.PolarsError as err:\n                error_handler(\n                    err=err,\n                    err_level='critical',\n                    message=str(err),\n                    lazy=collect_exceptions,\n                    logger=logger,\n                )\n\n            except (pa.errors.SchemaErrors, pa.errors.SchemaError) as err:\n                pandera_schema_errors_handler(\n                    err=err,\n                    lazy=collect_exceptions,\n                    logger=logger,\n                )\n                logger.info('Collecting validation errors')\n            # Pandera not implemented for polars some lazy validation.\n            # Run in again in eager mode to catch the error.\n            # This is a workaround for the issue.\n            except NotImplementedError:\n                try:\n                    logger.warning('Trying eager validation')\n                    dataframe.pipe(df_schema.validate)\n\n                except pl.exceptions.PolarsError as err:\n                    error_handler(\n                        err=err,\n                        err_level='critical',\n                        message=str(err),\n                        lazy=collect_exceptions,\n                        logger=logger,\n                    )\n\n                except pa.errors.SchemaError as err:\n                    pandera_schema_errors_handler(\n                        err=err,\n                        lazy=collect_exceptions,\n                        logger=logger,\n                    )\n\n                logger.info('Collecting eager validation errors')\n\n        except Exception as err:\n            exception_handler(\n                err=err,\n                err_level='critical',\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n\n        logger.info('DataFrame validation completed')\n</code></pre>"},{"location":"api/#dataguard.validator.validator.Validator.config_from_mapping","title":"config_from_mapping  <code>classmethod</code>","text":"<pre><code>config_from_mapping(\n    config: Mapping[str, str | Sequence | Mapping],\n    collect_exceptions: bool = True,\n    logger: logging.Logger = logger,\n) -&gt; Validator\n</code></pre> <p>Creates a Validator instance from a configuration mapping.</p> <p>Parameters:</p> Name Type Description Default <code>Mapping[str, str | Sequence | Mapping]</code> <p>Configuration mapping for the DataFrame schema.</p> required <code>bool</code> <p>Whether to collect exceptions during the schema creation. Defaults to True.</p> <code>True</code> <code>logging.Logger</code> <p>Logger instance for logging. Defaults to the module logger.</p> <code>logger</code> <p>Examples:</p> <p>The command is either a user-defined function or a string that maps to a function that will be used to validate the DataFrame.</p> <p>The following commands are available:</p> <pre><code>'is_equal_to',\n'is_equal_to_or_both_missing',\n'is_greater_than_or_equal_to',\n'is_greater_than',\n'is_less_than_or_equal_to',\n'is_less_than',\n'is_not_equal_to',\n'is_not_equal_to_and_not_both_missing',\n'is_unique',\n'is_duplicated',\n'is_in',\n'is_null',\n'is_not_null'\n</code></pre> <pre><code>&gt;&gt;&gt; config_input = {\n        \"name\": \"example_schema\",\n        \"columns\": [\n            {\n                \"id\": \"column1\",\n                \"data_type\": \"integer\",\n                \"nullable\": False,\n                \"unique\": True,\n                \"required\": True,\n                \"checks\": [\n                    {\n                        \"command\": \"is_equal_to\",\n                        \"subject\": [\"column2\"]\n                    }\n                ]\n            },\n        \"ids\": [\"column1\"],\n        \"metadata\": {\"description\": \"Example DataFrame schema\"},\n        \"checks\": [\n            {\n                'name': 'example_check',\n                'error_level': 'warning',\n                'error_msg': 'This is an example check',\n                'command': 'is_in',\n                'subject': ['column1'],\n                'arg_values': [1, 2]\n            }\n        ]\n    }\n</code></pre> <p>Returns:</p> Name Type Description <code>Validator</code> <code>Validator</code> <p>An instance of the Validator class with the schema created from the provided configuration mapping.</p> Source code in <code>src/dataguard/validator/validator.py</code> <pre><code>@classmethod\ndef config_from_mapping(\n    cls,\n    config: Mapping[str, str | Sequence | Mapping],\n    collect_exceptions: bool = True,\n    logger: logging.Logger = logger,\n) -&gt; Validator:\n    \"\"\"Creates a Validator instance from a configuration mapping.\n\n    Args:\n        config (Mapping[str, str | Sequence | Mapping]): Configuration\n            mapping for the DataFrame schema.\n        collect_exceptions (bool, optional): Whether to collect exceptions\n            during the schema creation. Defaults to True.\n        logger (logging.Logger, optional): Logger instance for logging.\n            Defaults to the module logger.\n\n    Examples:\n        The command is either a user-defined function or a string that\n        maps to a function that will be used to validate the DataFrame.\n\n        The following commands are available:\n\n            'is_equal_to',\n            'is_equal_to_or_both_missing',\n            'is_greater_than_or_equal_to',\n            'is_greater_than',\n            'is_less_than_or_equal_to',\n            'is_less_than',\n            'is_not_equal_to',\n            'is_not_equal_to_and_not_both_missing',\n            'is_unique',\n            'is_duplicated',\n            'is_in',\n            'is_null',\n            'is_not_null'\n\n        &gt;&gt;&gt; config_input = {\n                \"name\": \"example_schema\",\n                \"columns\": [\n                    {\n                        \"id\": \"column1\",\n                        \"data_type\": \"integer\",\n                        \"nullable\": False,\n                        \"unique\": True,\n                        \"required\": True,\n                        \"checks\": [\n                            {\n                                \"command\": \"is_equal_to\",\n                                \"subject\": [\"column2\"]\n                            }\n                        ]\n                    },\n                \"ids\": [\"column1\"],\n                \"metadata\": {\"description\": \"Example DataFrame schema\"},\n                \"checks\": [\n                    {\n                        'name': 'example_check',\n                        'error_level': 'warning',\n                        'error_msg': 'This is an example check',\n                        'command': 'is_in',\n                        'subject': ['column1'],\n                        'arg_values': [1, 2]\n                    }\n                ]\n            }\n\n    Returns:\n        Validator: An instance of the Validator class with the schema\n            created from the provided configuration mapping.\n\n    \"\"\"\n    validator = cls()\n    try:\n        validator.df_schema = get_df_schema(config)\n        logger.info('DFSchema created successfully')\n\n    except KeyError as err:\n        error_handler(\n            err=err,\n            err_level='critical',\n            message=f'Missing the following key in config input: {err.args[0]}',  # noqa: E501\n            lazy=collect_exceptions,\n            logger=logger,\n        )\n\n    except (AttributeError, TypeError) as err:\n        error_handler(\n            err=err,\n            err_level='critical',\n            message=f'Invalid config type: {err.args[0]}',\n            lazy=collect_exceptions,\n            logger=logger,\n        )\n\n    except ValidationError as err:\n        error_handler(\n            err=err,\n            err_level='critical',\n            message=f'Invalid config type: {[error[\"loc\"] for error in err.errors()]}',  # noqa: E501\n            lazy=collect_exceptions,\n            logger=logger,\n        )\n\n    except Exception as err:\n        exception_handler(\n            err=err,\n            err_level='critical',\n            lazy=collect_exceptions,\n            logger=logger,\n        )\n\n        logger.error('Failed to create DFSchema from configuration')\n\n    return validator\n</code></pre>"},{"location":"api/#dataguard.validator.validator.Validator.config_from_mapping(config)","title":"<code>config</code>","text":""},{"location":"api/#dataguard.validator.validator.Validator.config_from_mapping(collect_exceptions)","title":"<code>collect_exceptions</code>","text":""},{"location":"api/#dataguard.validator.validator.Validator.config_from_mapping(logger)","title":"<code>logger</code>","text":""},{"location":"api/#dataguard.validator.validator.Validator.validate","title":"validate","text":"<pre><code>validate(\n    dataframe: Mapping[str, list] | pl.DataFrame,\n    lazy_validation: bool = True,\n    collect_exceptions: bool = True,\n    logger: logging.Logger = logger,\n) -&gt; None\n</code></pre> <p>Validates a DataFrame against the defined schema.</p> <p>Parameters:</p> Name Type Description Default <code>Mapping[str, list] | pl.DataFrame</code> <p>The input data as a mapping or a Polars DataFrame.</p> required <code>bool</code> <p>Whether to perform lazy validation. Defaults to True.</p> <code>True</code> <code>bool</code> <p>Whether to collect exceptions during validation. Defaults to True.</p> <code>True</code> <code>logging.Logger</code> <p>Logger instance for logging. Defaults to the module logger.</p> <code>logger</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If an error occurs during validation and collect_exceptions is False.</p> Source code in <code>src/dataguard/validator/validator.py</code> <pre><code>def validate(\n    self,\n    dataframe: Mapping[str, list] | pl.DataFrame,\n    lazy_validation: bool = True,\n    collect_exceptions: bool = True,\n    logger: logging.Logger = logger,\n) -&gt; None:\n    \"\"\"Validates a DataFrame against the defined schema.\n\n    Args:\n        dataframe (Mapping[str, list] | pl.DataFrame): The input data\n            as a mapping or a Polars DataFrame.\n        lazy_validation (bool, optional): Whether to perform lazy validation.\n            Defaults to True.\n        collect_exceptions (bool, optional): Whether to collect exceptions\n            during validation. Defaults to True.\n        logger (logging.Logger, optional): Logger instance for logging.\n            Defaults to the module logger.\n\n    Raises:\n        Exception: If an error occurs during validation and\n            collect_exceptions is False.\n\n    \"\"\"  # noqa: E501\n    try:\n        if not getattr(self, 'df_schema', None):\n            logger.error('DataFrame schema is not defined')\n            return\n\n        logger.info('Starting DataFrame validation')\n        if isinstance(dataframe, Mapping):\n            dataframe = convert_mapping_to_dataframe(\n                dataframe=dataframe,\n                collect_exceptions=collect_exceptions,\n                logger=logger,\n            )\n\n        if not getattr(dataframe, 'shape', None):\n            logger.error('DataFrame is not valid')\n            return\n\n        logger.info(f'Building DataFrame schema {self.df_schema.name =}')\n        df_schema = self.df_schema.build()\n\n        try:\n            logger.info('Casting DataFrame Types')\n            dataframe = dataframe.cast({\n                col.id: validation_type_mapper[col.data_type]\n                for col in self.df_schema.columns\n                if col.id in dataframe.columns\n            })\n\n            logger.info('Starting DataFrame validation')\n            dataframe.pipe(df_schema.validate, lazy=lazy_validation)\n\n        except pl.exceptions.PolarsError as err:\n            error_handler(\n                err=err,\n                err_level='critical',\n                message=str(err),\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n\n        except (pa.errors.SchemaErrors, pa.errors.SchemaError) as err:\n            pandera_schema_errors_handler(\n                err=err,\n                lazy=collect_exceptions,\n                logger=logger,\n            )\n            logger.info('Collecting validation errors')\n        # Pandera not implemented for polars some lazy validation.\n        # Run in again in eager mode to catch the error.\n        # This is a workaround for the issue.\n        except NotImplementedError:\n            try:\n                logger.warning('Trying eager validation')\n                dataframe.pipe(df_schema.validate)\n\n            except pl.exceptions.PolarsError as err:\n                error_handler(\n                    err=err,\n                    err_level='critical',\n                    message=str(err),\n                    lazy=collect_exceptions,\n                    logger=logger,\n                )\n\n            except pa.errors.SchemaError as err:\n                pandera_schema_errors_handler(\n                    err=err,\n                    lazy=collect_exceptions,\n                    logger=logger,\n                )\n\n            logger.info('Collecting eager validation errors')\n\n    except Exception as err:\n        exception_handler(\n            err=err,\n            err_level='critical',\n            lazy=collect_exceptions,\n            logger=logger,\n        )\n\n    logger.info('DataFrame validation completed')\n</code></pre>"},{"location":"api/#dataguard.validator.validator.Validator.validate(dataframe)","title":"<code>dataframe</code>","text":""},{"location":"api/#dataguard.validator.validator.Validator.validate(lazy_validation)","title":"<code>lazy_validation</code>","text":""},{"location":"api/#dataguard.validator.validator.Validator.validate(collect_exceptions)","title":"<code>collect_exceptions</code>","text":""},{"location":"api/#dataguard.validator.validator.Validator.validate(logger)","title":"<code>logger</code>","text":""},{"location":"api/#dataguard.core.utils.enums.CheckCases","title":"CheckCases","text":"<p>               Bases: <code>Enum</code></p> <p>Enum representing different types of check cases.</p> Source code in <code>src/dataguard/core/utils/enums.py</code> <pre><code>class CheckCases(Enum):\n    \"\"\"Enum representing different types of check cases.\"\"\"\n\n    CONDITION = 'condition'\n    CONJUNCTION = 'conjunction'\n    DISJUNCTION = 'disjunction'\n</code></pre>"},{"location":"api/#dataguard.core.utils.enums.ErrorLevel","title":"ErrorLevel","text":"<p>               Bases: <code>Enum</code></p> <p>Enum representing different levels of error severity.</p> Source code in <code>src/dataguard/core/utils/enums.py</code> <pre><code>class ErrorLevel(Enum):\n    \"\"\"Enum representing different levels of error severity.\"\"\"\n\n    WARNING = 'warning'\n    ERROR = 'error'\n    CRITICAL = 'critical'\n</code></pre>"},{"location":"api/#dataguard.core.utils.enums.ValidationType","title":"ValidationType","text":"<p>               Bases: <code>Enum</code></p> <p>Enum representing different validation types for DataFrame columns.</p> Source code in <code>src/dataguard/core/utils/enums.py</code> <pre><code>class ValidationType(Enum):\n    \"\"\"Enum representing different validation types for DataFrame columns.\"\"\"\n\n    DATE = 'date'\n    DATETIME = 'datetime'\n    BOOL = 'boolean'\n    FLOAT = 'float'\n    INT = 'integer'\n    STR = 'string'\n    CAT = 'categorical'\n    DECIMAL = 'decimal'\n</code></pre>"},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector","title":"ErrorCollector  <code>cached</code>","text":"<p>ErrorCollector class for collecting errors during validation.</p> Source code in <code>src/dataguard/error_report/error_collector.py</code> <pre><code>@cache\nclass ErrorCollector:\n    \"\"\"ErrorCollector class for collecting errors during validation.\"\"\"\n\n    COUNTER = 0\n\n    def __init__(self):\n        self.__errors = []\n        self.__exceptions = []\n\n    def add_unknown_exception(\n        self,\n        exception: ExceptionSchema,\n    ) -&gt; None:\n        \"\"\"Adds an unknown exception to the collector.\n\n        Args:\n            exception (ExceptionSchema): The exception to add.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.__exceptions.append(exception)\n\n    def add_error_report(\n        self,\n        error_report: ErrorReportSchema,\n    ) -&gt; None:\n        \"\"\"Adds an error report to the collector.\n\n        Args:\n            error_report (ErrorReportSchema): The error report to add.\n\n        Returns:\n            None\n\n        \"\"\"\n        self.__errors.append(error_report)\n        self.COUNTER += error_report.total_errors\n\n    def get_errors(self) -&gt; ErrorCollectorSchema:\n        \"\"\"Returns the collected errors and exceptions.\n\n        Returns:\n            ErrorCollectorSchema: A schema containing the collected errors and exceptions.\n\n        \"\"\"  # noqa: E501\n        return ErrorCollectorSchema(\n            error_reports=self.__errors, exceptions=self.__exceptions\n        )\n\n    def clear_errors(self) -&gt; None:\n        \"\"\"Clears the collected errors and exceptions.\"\"\"\n        self.__errors.clear()\n        self.__exceptions.clear()\n        self.COUNTER = 0\n</code></pre>"},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector.add_error_report","title":"add_error_report","text":"<pre><code>add_error_report(error_report: ErrorReportSchema) -&gt; None\n</code></pre> <p>Adds an error report to the collector.</p> <p>Parameters:</p> Name Type Description Default <code>ErrorReportSchema</code> <p>The error report to add.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/dataguard/error_report/error_collector.py</code> <pre><code>def add_error_report(\n    self,\n    error_report: ErrorReportSchema,\n) -&gt; None:\n    \"\"\"Adds an error report to the collector.\n\n    Args:\n        error_report (ErrorReportSchema): The error report to add.\n\n    Returns:\n        None\n\n    \"\"\"\n    self.__errors.append(error_report)\n    self.COUNTER += error_report.total_errors\n</code></pre>"},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector.add_error_report(error_report)","title":"<code>error_report</code>","text":""},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector.add_unknown_exception","title":"add_unknown_exception","text":"<pre><code>add_unknown_exception(exception: ExceptionSchema) -&gt; None\n</code></pre> <p>Adds an unknown exception to the collector.</p> <p>Parameters:</p> Name Type Description Default <code>ExceptionSchema</code> <p>The exception to add.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/dataguard/error_report/error_collector.py</code> <pre><code>def add_unknown_exception(\n    self,\n    exception: ExceptionSchema,\n) -&gt; None:\n    \"\"\"Adds an unknown exception to the collector.\n\n    Args:\n        exception (ExceptionSchema): The exception to add.\n\n    Returns:\n        None\n\n    \"\"\"\n    self.__exceptions.append(exception)\n</code></pre>"},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector.add_unknown_exception(exception)","title":"<code>exception</code>","text":""},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector.clear_errors","title":"clear_errors","text":"<pre><code>clear_errors() -&gt; None\n</code></pre> <p>Clears the collected errors and exceptions.</p> Source code in <code>src/dataguard/error_report/error_collector.py</code> <pre><code>def clear_errors(self) -&gt; None:\n    \"\"\"Clears the collected errors and exceptions.\"\"\"\n    self.__errors.clear()\n    self.__exceptions.clear()\n    self.COUNTER = 0\n</code></pre>"},{"location":"api/#dataguard.error_report.error_collector.ErrorCollector.get_errors","title":"get_errors","text":"<pre><code>get_errors() -&gt; ErrorCollectorSchema\n</code></pre> <p>Returns the collected errors and exceptions.</p> <p>Returns:</p> Name Type Description <code>ErrorCollectorSchema</code> <code>ErrorCollectorSchema</code> <p>A schema containing the collected errors and exceptions.</p> Source code in <code>src/dataguard/error_report/error_collector.py</code> <pre><code>def get_errors(self) -&gt; ErrorCollectorSchema:\n    \"\"\"Returns the collected errors and exceptions.\n\n    Returns:\n        ErrorCollectorSchema: A schema containing the collected errors and exceptions.\n\n    \"\"\"  # noqa: E501\n    return ErrorCollectorSchema(\n        error_reports=self.__errors, exceptions=self.__exceptions\n    )\n</code></pre>"},{"location":"api/#dataguard.error_report.error_schemas.BasicExceptionSchema","title":"BasicExceptionSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Basic schema for exceptions.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the error.</p> <code>message</code> <code>str</code> <p>Message describing the error.</p> Source code in <code>src/dataguard/error_report/error_schemas.py</code> <pre><code>class BasicExceptionSchema(BaseModel):\n    \"\"\"Basic schema for exceptions.\n\n    Attributes:\n        type (str): Type of the error.\n        message (str): Message describing the error.\n\n    \"\"\"\n\n    type: str\n    message: str\n    level: ErrorLevel\n</code></pre>"},{"location":"api/#dataguard.error_report.error_schemas.DFErrorSchema","title":"DFErrorSchema","text":"<p>               Bases: <code>ErrorSchema</code></p> <p>Schema for errors that occur during DataFrame validation.</p> <p>Attributes:</p> Name Type Description <code>column_names</code> <code>list[str] | str</code> <p>Names of the columns where the error occurred.</p> <code>row_ids</code> <code>list[int]</code> <p>IDs of the rows where the error occurred.</p> <code>idx_columns</code> <code>list[str]</code> <p>Index columns used for identifying errors.</p> <code>level</code> <code>str</code> <p>Level of the error, e.g., 'error', 'warning'.</p> <code>message</code> <code>str</code> <p>Message describing the error.</p> <code>title</code> <code>str</code> <p>Title of the error.</p> Source code in <code>src/dataguard/error_report/error_schemas.py</code> <pre><code>class DFErrorSchema(ErrorSchema):\n    \"\"\"Schema for errors that occur during DataFrame validation.\n\n    Attributes:\n        column_names (list[str] | str): Names of the columns where the error occurred.\n        row_ids (list[int]): IDs of the rows where the error occurred.\n        idx_columns (list[str]): Index columns used for identifying errors.\n        level (str): Level of the error, e.g., 'error', 'warning'.\n        message (str): Message describing the error.\n        title (str): Title of the error.\n\n    \"\"\"  # noqa: E501\n\n    column_names: list[str]\n    row_ids: list[int]\n    idx_columns: list[str]\n    title: str\n    traceback: str | None = None\n</code></pre>"},{"location":"api/#dataguard.error_report.error_schemas.ErrorCollectorSchema","title":"ErrorCollectorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for collecting errors and exceptions during validation.</p> <p>Attributes:</p> Name Type Description <code>error_reports</code> <code>list[ErrorReportSchema]</code> <p>List of error reports.</p> <code>exceptions</code> <code>list[ExceptionSchema]</code> <p>List of exceptions that occurred during validation.</p> Source code in <code>src/dataguard/error_report/error_schemas.py</code> <pre><code>class ErrorCollectorSchema(BaseModel):\n    \"\"\"Schema for collecting errors and exceptions during validation.\n\n    Attributes:\n        error_reports (list[ErrorReportSchema]): List of error reports.\n        exceptions (list[ExceptionSchema]): List of exceptions that occurred during validation.\n\n    \"\"\"  # noqa: E501\n\n    error_reports: list[ErrorReportSchema] = []\n    exceptions: list[ExceptionSchema] = []\n</code></pre>"},{"location":"api/#dataguard.error_report.error_schemas.ErrorReportSchema","title":"ErrorReportSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Schema for error reports generated during validation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the error report.</p> <code>errors</code> <code>list[ErrorSchema]</code> <p>List of errors found in the DataFrame.</p> <code>total_errors</code> <code>int</code> <p>Total number of errors in the report.</p> <code>id</code> <code>int</code> <p>Unique identifier for the error report.</p> Source code in <code>src/dataguard/error_report/error_schemas.py</code> <pre><code>class ErrorReportSchema(BaseModel):\n    \"\"\"Schema for error reports generated during validation.\n\n    Attributes:\n        name (str): Name of the error report.\n        errors (list[ErrorSchema]): List of errors found in the DataFrame.\n        total_errors (int): Total number of errors in the report.\n        id (int): Unique identifier for the error report.\n\n    \"\"\"\n\n    name: str\n    errors: list[ErrorSchema]\n    total_errors: int\n    id: str\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/#dataguard.error_report.error_schemas.ErrorSchema","title":"ErrorSchema","text":"<p>               Bases: <code>BasicExceptionSchema</code></p> <p>Schema for errors that occur during validation.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the error.</p> <code>message</code> <code>str</code> <p>Message describing the error.</p> <code>title</code> <code>str</code> <p>Title of the error.</p> <code>traceback</code> <code>str</code> <p>Traceback of the error.</p> Source code in <code>src/dataguard/error_report/error_schemas.py</code> <pre><code>class ErrorSchema(BasicExceptionSchema):\n    \"\"\"Schema for errors that occur during validation.\n\n    Attributes:\n        type (str): Type of the error.\n        message (str): Message describing the error.\n        title (str): Title of the error.\n        traceback (str): Traceback of the error.\n    \"\"\"\n\n    title: str\n    traceback: str\n</code></pre>"},{"location":"api/#dataguard.error_report.error_schemas.ExceptionSchema","title":"ExceptionSchema","text":"<p>               Bases: <code>BasicExceptionSchema</code></p> <p>Schema for unknown exceptions that occur during validation.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of the error.</p> <code>message</code> <code>str</code> <p>Message describing the error.</p> <code>level</code> <code>ErrorLevel</code> <p>Level of the error.</p> <code>traceback</code> <code>str</code> <p>Traceback of the error.</p> Source code in <code>src/dataguard/error_report/error_schemas.py</code> <pre><code>class ExceptionSchema(BasicExceptionSchema):\n    \"\"\"Schema for unknown exceptions that occur during validation.\n\n    Attributes:\n        type (str): Type of the error.\n        message (str): Message describing the error.\n        level (ErrorLevel): Level of the error.\n        traceback (str): Traceback of the error.\n\n    \"\"\"\n\n    traceback: str\n</code></pre>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#dataguard-workflow","title":"Dataguard workflow","text":"<p>getting_started.py<pre><code>from dataguard import Validator\n\nconfig = {\n            'name': 'Minimal Config',\n            'columns': [],\n            'ids': [],\n            'metadata': {},\n            'checks': [],\n        }\n\ndf = {}  # You can also pass a polars DataFrame here\n\nvalidator = Validator.config_from_mapping(config)\n\nvalidator.validate(df)\n</code></pre> 1 - Create a minimal validation configuration with the required fields: name, columns, ids, metadata and checks.</p> <p>2 - Instantiate a <code>Validator</code> using <code>config_from_mapping()</code> method.</p> <p>3 - Validate the dataframe <code>df</code> calling <code>validate()</code></p> <p>While this example uses empty lists and an empty DataFrame for simplicity, it illustrates the core three-step process: define your validation rules in a configuration, create a validator from that configuration, and apply it to your data.</p>"},{"location":"getting_started/#validating-real-world-constraints","title":"Validating real-world constraints","text":"<p>Consider an <code>age</code> column configuration that demonstrates Dataguard's data quality enforcement capabilities:</p> <ul> <li>Type Safety: Enforcing <code>integer</code> data type prevents string or float contamination</li> <li>Null Prevention: <code>nullable: False</code> ensures no missing age values slip through</li> <li>Range Validation: Age bounds <code>[0-150)</code> catch unrealistic values like negative ages or extreme outliers</li> <li>Business Logic: Reflects real-world constraints for human age data</li> </ul> getting_started.py<pre><code>config_age = {\n    'name': 'Age must be not null, grater than or equal to 0 and less than 150',\n    'columns': [\n        {\n            'id': 'age',\n            'data_type': 'integer',\n            'nullable': False,\n            'unique': False,\n            'required': True,\n            'checks': [\n                {\n                    'command': 'is_greater_than_or_equal_to',\n                    'arg_values': [0],\n                },\n                {\n                    'command': 'is_less_than',\n                    'arg_values': [150],\n                }\n            ],\n        },\n    ],\n    'ids': [],\n    'metadata': {},\n    'checks': [],\n}\n\ndf_age = pl.DataFrame({\n    'age': [2, 30, None, -5, 150, 45, 50],\n})\n\nvalidator = Validator.config_from_mapping(config_age)\n\nvalidator.validate(df_age)\n</code></pre>"},{"location":"getting_started/#analyzing-error-report","title":"Analyzing error report","text":"<p>Each validation instance that catches validation errors creates an <code>ErrorReport</code> that is collected to the <code>ErrorCollector</code> under the hood. </p> <p>Another way to access the <code>ErrorCollector</code> is calling the <code>Validator</code>'s <code>error_collector</code> property.</p> getting_started.py<pre><code>from dataguard import ErrorCollector\n\nprint(ErrorCollector().get_errors().model_dump_json(indent=3))\n\n#{\n#   \"error_reports\": [\n#      {\n#         \"name\": \"Age must be not null, grater than or equal to 0 and less than 150\",\n#         \"errors\": [\n#            {\n#               \"type\": \"SchemaErrorReason.SERIES_CONTAINS_NULLS\",\n#               \"message\": \"non-nullable column 'age' contains null values\",\n#               \"level\": \"error\",\n#               \"title\": \"Not_Nullable\",\n#               \"traceback\": null\n#            },\n#            {\n#               \"type\": \"SchemaErrorReason.DATAFRAME_CHECK\",\n#               \"message\": \"Column 'age' failed validator number 0: &lt;Check error: The column under validation is greater than or equal to \\\"0\\\"&gt; failure case examples: [{'age': -5}]\",\n#               \"level\": \"error\",\n#               \"title\": \"Is greater than or equal to\",\n#               \"traceback\": null\n#            },\n#            {\n#               \"type\": \"SchemaErrorReason.DATAFRAME_CHECK\",\n#               \"message\": \"Column 'age' failed validator number 1: &lt;Check error: The column under validation is less than \\\"150\\\"&gt; failure case examples: [{'age': 150}]\",\n#               \"level\": \"error\",\n#               \"title\": \"Is less than\",\n#               \"traceback\": null\n#            }\n#         ],\n#         \"total_errors\": 3,\n#         \"id\": \"feab21d0-63be-48a1-9134-7071d9095687\"\n#      }\n#   ],\n#   \"exceptions\": []\n#}\n</code></pre> <p>Let's deep dive into the second error <code>Is greater than or equal to</code>.</p> getting_started.py<pre><code>print(ErrorCollector().get_errors().error_reports[0].errors[1].model_dump_json(indent=3))\n\n#{\n#   \"type\": \"SchemaErrorReason.DATAFRAME_CHECK\",\n#   \"message\": \"Column 'age' failed validator number 0: &lt;Check error: The column under validation is greater than or equal to \\\"0\\\"&gt; failure case examples: [{'age': -5}]\",\n#   \"level\": \"error\",\n#   \"title\": \"Is greater than or equal to\",\n#   \"traceback\": null,\n#   \"column_names\": [\n#      \"age\"\n#   ],\n#   \"row_ids\": [\n#      3\n#   ],\n#   \"idx_columns\": []\n#}\n</code></pre> <p>The <code>DFErrorSchema</code> return provides detailed information about a specific validation error:</p>"},{"location":"getting_started/#dferrorschema-fields","title":"DFErrorSchema Fields","text":"<ul> <li> <p>type: The error category (SchemaErrorReason.DATAFRAME_CHECK) indicating this is a column-level validation failure</p> </li> <li> <p>message: Descriptive error text explaining what failed, including the specific check and example failure cases</p> </li> <li> <p>level: Error severity (ErrorLevel.ERROR) - can be error, warning, or info</p> </li> <li> <p>title: Human-readable error name (Is greater than or equal to) matching the validation rule</p> </li> <li> <p>traceback: Stack trace information (None if not available) for debugging</p> </li> <li> <p>column_names: List of affected columns (['age']) - useful for multi-column validations</p> </li> <li> <p>row_ids: Specific row indices that failed validation ([3]) - enables precise error location</p> </li> <li> <p>idx_columns: Index column information ([]) - empty when not using custom indices</p> </li> </ul> <p>In this example, the error shows that row <code>3</code> in the <code>'age'</code> column contains the value <code>-5</code>, which violates the \"greater than or equal to 0\" constraint. This granular information allows you to pinpoint exactly which data points need fixing and why they failed validation.</p>"},{"location":"how-to-create_checks/","title":"How to create checks","text":""},{"location":"how-to-create_checks/#simple-check-expression","title":"Simple check expression","text":"<p>To define a simple check expression, the only required argument is <code>command</code>. But we usually need to pass a few arguments to be tested. The most important are <code>arg_values</code> and <code>arg_column</code>. Which values \u200b\u200bare tested against the column under test or which other column is tested against the column under test, respectively.</p> <p>getting_started.py<pre><code>            'checks': [\n                {\n                    'command': 'is_greater_than_or_equal_to',\n                    'arg_values': [0],\n                },\n</code></pre> In human-readable text: <code>check if a given column is greater than or equal to 0</code>.</p> <p>However, you can also define custom <code>name</code>, <code>error_level</code> and <code>error_msg</code> that will be further parsed by ErrorCollector.</p> <pre><code>name: &lt;string or empty&gt;\nerror_level: &lt;empty or one of: 'warning', 'error', 'critical'&gt;\nerror_msg: &lt;string or empty&gt;\ncommand: &lt;string or a function*&gt;\nsubject: &lt;empty or a list with column names*&gt;\narg_values: &lt;empty or a list of args&gt;\narg_columns: &lt;empty or a list of column names&gt;\n</code></pre>"},{"location":"how-to-create_checks/#command","title":"command","text":"<p>It can be one of:</p> <pre><code>'is_equal_to',\n'is_equal_to_or_both_missing',\n'is_greater_than_or_equal_to',\n'is_greater_than',\n'is_less_than_or_equal_to',\n'is_less_than',\n'is_not_equal_to',\n'is_not_equal_to_and_not_both_missing',\n'is_unique',\n'is_duplicated',\n'is_in',\n'is_null',\n'is_not_null'\n</code></pre>"},{"location":"how-to-create_checks/#complex-check-expression","title":"Complex check expression","text":"<p>We can combine simple expressions to create complex ones using check cases. Three types are available:</p> <pre><code>'condition'\n'conjunction'\n'disjunction'\n</code></pre> <p>Let's perform the same check we did before for the <code>age</code> column but combine the checks into a <code>conjunction</code> case.</p> checks.py<pre><code>config_age = {\n    'name': 'Age must be not null, grater than or equal to 0 and less than 150',\n    'columns': [\n        {\n            'id': 'age',\n            'data_type': 'integer',\n            'nullable': False,\n            'unique': False,\n            'required': True,\n            'checks': [\n                    {\n                    'check_case': 'conjunction',\n                    'expressions': [\n                        {\n                        'command': 'is_greater_than_or_equal_to', \n                        'arg_values': [0]\n                        },\n                        {\n                        'command': 'is_less_than', \n                        'arg_values': [150]\n                        }\n                    ]\n                },\n                ]\n        },\n    ],\n    'ids': [],\n    'metadata': {},\n    'checks': [],\n}\n\ndf_age = pl.DataFrame({\n    'age': [2, 30, None, -5, 150, 45, 50],\n})\n\nvalidator = Validator.config_from_mapping(config_age)\n\nvalidator.validate(df_age)\n\nprint(ErrorCollector().get_errors().model_dump_json(indent=3))\n\n#{\n#   \"error_reports\": [\n#      {\n#         \"name\": \"Age must be not null, grater than or equal to 0 and less than 150\",\n#         \"errors\": [\n#            {\n#               \"type\": \"SchemaErrorReason.SERIES_CONTAINS_NULLS\",\n#               \"message\": \"non-nullable column 'age' contains null values\",\n#               \"level\": \"error\",\n#               \"title\": \"Not_Nullable\",\n#               \"traceback\": null\n#            },\n#            {\n#               \"type\": \"SchemaErrorReason.DATAFRAME_CHECK\",\n#               \"message\": \"Column 'age' failed validator number 0: &lt;Check error: The column under validation is greater than or equal to \\\"0\\\" and The column under validation is less than \\\"150\\\"&gt; failure case examples: [{'age': -5}, {'age': 150}]\",\n#               \"level\": \"error\",\n#               \"title\": \"Is greater than or equal to and Is less than\",\n#               \"traceback\": null\n#            }\n#         ],\n#         \"total_errors\": 2,\n#         \"id\": \"f7591494-0750-4757-97fe-e57ba5ed7a5b\"\n#      }\n#   ],\n#   \"exceptions\": []\n#}\n</code></pre> <p>Complex check expressions always have the same structure and can be combined in nested expressions.</p> <pre><code>'check_case': &lt;conjunction/disjunction/condition&gt;\n'expressions': [&lt;2 expressions that can be simple or another complex one&gt;]\n</code></pre> <p>Notice that instead of 3 errors being collected, we now only have 2, meaning that even though the same validations are performed, the report output is different.</p>"},{"location":"how-to-create_checks/#tailor-made-check-functions","title":"Tailor-made check functions","text":"<p>Users can also define their own verification functions. The only requirement is to follow the same signature pattern below.</p> <p><code>data</code> always receives an object that has a <code>.lazyframe</code> (a polar <code>LazyFrame</code>) and <code>.key</code>, which is the name of the column to be validated.</p> <p>Finally, it must return a polar <code>LazyFrame</code> with a binary column.</p> checks.py<pre><code>def is_between(data, arg_values=None, arg_columns=None, subject=None):\n        return data.lazyframe.select(\n            pl.col(data.key).is_between(arg_values[0], arg_values[1], closed='left')\n        )\n</code></pre> <p>Let's use the above function to perform the same check we did before for the <code>age</code> column. We'll also use other fields to understand how they modify the report output.</p> <p>checks.py<pre><code>config_age = {\n    'name': 'Age must be not null, grater than or equal to 0 and less than 150',\n    'columns': [\n        {\n            'id': 'age',\n            'data_type': 'integer',\n            'nullable': False,\n            'unique': False,\n            'required': True,\n            'checks': [\n                {\n                    'name': 'Tailor-made function check: is_between',\n                    'error_level': 'warning',\n                    'error_msg': 'Age must be between 0 (inclusive) and 150 (exclusive)',\n                    'command': is_between,\n                    'arg_values': [0, 150],\n                },\n            ],\n        },\n    ],\n    'ids': [],\n    'metadata': {},\n    'checks': [],\n}\n\ndf_age = pl.DataFrame({\n    'age': [2, 30, None, -5, 150, 45, 50],\n})\n\nvalidator = Validator.config_from_mapping(config_age)\n\nvalidator.validate(df_age)\n\nprint(ErrorCollector().get_errors().model_dump_json(indent=3))\n\n\n#{\n#   \"error_reports\": [\n#      {\n#         \"name\": \"Age must be not null, grater than or equal to 0 and less than 150\",\n#         \"errors\": [\n#            {\n#               \"type\": \"SchemaErrorReason.SERIES_CONTAINS_NULLS\",\n#               \"message\": \"non-nullable column 'age' contains null values\",\n#               \"level\": \"error\",\n#               \"title\": \"Not_Nullable\",\n#               \"traceback\": null\n#            },\n#            {\n#               \"type\": \"SchemaErrorReason.DATAFRAME_CHECK\",\n#               \"message\": \"Column 'age' failed validator number 0: &lt;Check warning: Age must be between 0 (inclusive) and 150 (exclusive)&gt; failure case examples: [{'age': -5}, {'age': 150}]\",\n#               \"level\": \"warning\",\n#               \"title\": \"Tailor-made function check: is_between\",\n#               \"traceback\": null\n#            }\n#         ],\n#         \"total_errors\": 2,\n#         \"id\": \"3fcde816-4789-40d9-a4d1-34ed1674b23d\"\n#      }\n#   ],\n#   \"exceptions\": []\n#}\n</code></pre> Instead of creating two separate checks, we implemented our own function as a single test. Notice that instead of 3 errors being collected, we now only have 2, meaning that even though the same validations are performed, the report output is different.</p>"},{"location":"how-to-create_checks/#dataframe-level-expressions","title":"DataFrame level expressions","text":"<p>We can also define checks at the DataFrame level. When applying a check to multiple columns, you can either copy the same check to each column or define it once at the DataFrame level.</p> <p>The check must go into the check container at the config level and not inside a column. Apart from that, you can either check all columns or define a list of columns using the <code>subject</code> argument that receives a list of column names.</p>"}]}